# Project Brief: American Nerd Marketplace

## Executive Summary

A multi-stage expert marketplace that transforms your product ideas into reality through the complete BMAD (Bmad Subroutine Library) workflow - from brainstorming and planning to development and quality validation. Each stage connects you with specialized experts who execute and validate AI-assisted work, with escrow-protected payments and guaranteed quality.

**The Problem You Face:** You have great ideas for software products, but the path from idea to shipped code is overwhelming. Traditional freelancing means vague proposals, constant back-and-forth, and anxiety about quality. AI coding tools promise speed but deliver slop. You need the complete workflow - not just developers, but expert guidance on requirements, architecture, design, and validation.

**How We Solve It:** We monetize the entire BMAD planning and development workflow by connecting you with expert practitioners at each stage. AI agents assist, human experts validate and improve. Every deliverable is escrow-protected and quality-validated before payment releases.

**The Complete Workflow:**

**Planning Phase:**
1. **Analyst** (optional) - Brainstorming, market research, competitive analysis
2. **PM Expert** - Transforms your brief into comprehensive PRD (Product Requirements Document)
3. **Architect Expert** - Creates technical architecture specifications from PRD
4. **UX Expert** - Designs user experience and interfaces from PRD + Architecture

**Development Phase:**
5. **Developer** - Implements stories following all planning documentation
6. **QA Reviewer** - Validates code quality, brief alignment, and production-readiness

**What You Get:**
- **Complete project documentation** - PRD, architecture, design docs created by expert practitioners (not just AI output)
- **Expert validation at every stage** - Human judgment ensures AI assistance produces quality, not slop
- **True async collaboration** - Comprehensive docs eliminate communication overhead; experts work from documentation "mother ship"
- **Pay-per-stage safety** - Escrow protection at each phase; money releases only after quality validation
- **Earn across multiple roles** - Same indie makers can be clients, PMs, architects, UX experts, developers, or QA reviewers

**How It Works:**
1. Create project brief (AI-assisted) → Post to platform
2. PM expert bids to create your PRD → You fund escrow, expert delivers, platform validates
3. Architect expert bids to create architecture docs → Escrow-protected delivery
4. UX expert bids to create design → Escrow-protected delivery
5. Project decomposed into stories → Developers bid on implementation
6. Developers build sequentially → QA reviewers validate each story
7. You receive complete, production-ready software with full documentation

**Platform Fee:** $100 + 5% per stage (story-level for development, per-deliverable for planning)

**Bottom Line:** Get your ideas built by real experts with real accountability at every stage - from planning to deployment - without the chaos of traditional freelancing or the quality risks of AI-only tools.

---

## Problem Statement

**Current State and Pain Points**

Indie makers and non-technical entrepreneurs face a critical bottleneck when trying to bring software ideas to life. The traditional paths all have fatal flaws:

**Traditional freelancing** creates communication chaos:
- Vague project descriptions lead to endless back-and-forth clarification
- Scope creep and budget overruns are the norm, not the exception
- Trust is a gamble - you hope the developer understands your vision and delivers quality

**Fully autonomous AI coding tools** promise speed but deliver slop:
- AI-generated code lacks the judgment, taste, and real-world context that skilled developers bring
- The "AI slop" stigma is real - nobody wants to ship products that feel robotic, buggy, or poorly thought-through
- Production-ready software requires human craftsmanship and accountability that AI can't provide

**Development agencies** solve quality with expert human talent but price out indie makers entirely.

The result: Most indie maker software ideas never ship because there's no affordable, reliable path from concept to quality code built by real developers.

**Impact of the Problem**

- **For idea holders**: Great product ideas die in the requirements phase. The gap between "I have an idea" and "I have shippable code built by skilled developers" feels insurmountable without spending thousands on agencies or settling for AI-generated slop.

- **For developers**: Talented indie developers waste their expertise on clarification calls, scope negotiation, and fixing miscommunication instead of doing what they're great at - building excellent software.

- **Economic impact**: Thousands of viable products never reach the market because the idea-to-implementation process doesn't properly value or utilize developer expertise.

- **Cultural impact**: The rise of AI slop has created justified skepticism. People want human craftsmanship and accountability, but current options make it prohibitively expensive or chaotic to access the skilled developers who can deliver it.

**Why Existing Solutions Fall Short**

**Freelance platforms (Upwork, Fiverr)** match people but don't empower developers to do their best work:
- They leave brief creation entirely to clients, resulting in vague, incomplete specifications
- They require constant synchronous communication, wasting developer time and limiting who can work together
- They offer weak quality enforcement - trust is based on reviews, not validation of actual work
- The "race to the bottom" on pricing undervalues developer expertise and incentivizes cutting corners

**AI coding tools (Cursor, Copilot, autonomous agents)** boost productivity but can't replace developer judgment:
- They lack the contextual wisdom to make product decisions or understand user needs
- Code quality varies wildly - the AI slop problem is pervasive
- No accountability when things break or don't meet requirements
- Users still need developer expertise to validate, review, and ship with confidence

**Development agencies** provide quality through experienced developers but at $10k-50k+ price points that exclude indie makers.

**The Missing Solution: Making Developer Expertise Accessible**

We're at a cultural inflection point. AI-generated slop has created a counter-movement: people actively want human expertise, craftsmanship, and accountability. They're willing to pay developers fairly for it - **if there's a reliable, affordable way to collaborate.**

The market is demanding a solution that respects both sides: leverage AI's strengths (structuring requirements, assisting execution) while empowering human developers to apply their judgment, taste, and expertise. The platform that solves this first - making developer expertise accessible and rewarding through standardization - wins the next decade of indie software development.

---

## Proposed Solution

Our platform solves the "idea to quality code" problem by monetizing the complete BMAD workflow as a multi-stage expert marketplace. Each BMAD agent role becomes an earning opportunity for human practitioners who validate and improve AI-assisted work.

**Core Concept and Approach**

We make expert software development accessible by orchestrating the entire planning and development workflow through specialized marketplaces. Think of it as "GitHub Actions for human development" - standardized workflow stages (planning → development → validation), AI assistance at each step, human experts ensure quality, escrow protection throughout.

**The Six-Stage Expert Marketplace:**

**Planning Marketplaces (Documentation Creation):**

1. **Analyst Marketplace** (Optional): Brainstorming and research experts help validate ideas
   - Market research, competitive analysis, opportunity assessment
   - AI-assisted research with human insight and strategic recommendations
   - Deliverable: Brainstorming session results, market analysis report

2. **PM Marketplace**: Product management experts create comprehensive PRDs
   - Transform client brief into detailed Product Requirements Document
   - AI-assisted PRD generation with PM expert validation and refinement
   - Deliverable: Complete PRD (problem, solution, users, features, success criteria, epics)

3. **Architect Marketplace**: Technical architecture experts design system specifications
   - Create technical architecture from PRD requirements
   - AI-assisted architecture design with expert validation of technical decisions
   - Deliverable: Architecture documentation (system design, tech stack, data models, APIs, security)

4. **UX Marketplace**: User experience experts design interfaces and flows
   - Design user experience and interfaces from PRD + Architecture
   - AI-assisted design with UX expert refinement and user-centered validation
   - Deliverable: Design documentation (user flows, wireframes, component specs, interaction patterns)

**Development Marketplaces (Implementation & Validation):**

5. **Developer Marketplace**: Developers implement stories following complete documentation
   - Build features according to PRD, architecture, and design specs
   - Work asynchronously using any tools, guided by comprehensive "mother ship" documentation
   - Deliverable: Working code delivered via GitHub PR, meeting acceptance criteria

6. **QA Marketplace**: Quality assurance experts validate work before payment release
   - Automated checks + human expert review of code quality and spec alignment
   - Assess both letter AND spirit of requirements using full documentation context
   - Deliverable: QA approval (or revision requests with detailed feedback)

**Key Differentiators from Existing Solutions**

**vs. Traditional Freelance Platforms:**
- **Complete workflow coverage**: Not just developer matching - we orchestrate planning, architecture, design, development, and QA
- **Expert marketplaces at each stage**: Access to specialized PMs, architects, UX designers, not just developers
- **Documentation-driven async**: Comprehensive BMAD docs eliminate communication overhead entirely
- **Multi-stage escrow protection**: Payment safety at every phase, not just final delivery
- **Native cryptocurrency payments**: True global access for experts in regions with unstable fiat currencies

**vs. AI Coding Tools:**
- **Human validation layer**: AI assists, experts validate - ensures quality over speed-only approaches
- **Complete planning coverage**: AI can't create strategic PRDs, architecture decisions, or UX design alone - experts provide judgment
- **Accountability at every stage**: Real humans responsible for deliverables, not "AI did it" excuses
- **Anti-slop positioning**: Platform brand becomes trust certification that work is expert-validated, not just AI-generated

**vs. Development Agencies:**
- **Unbundled expertise**: Pay for PM separately from architect, from developer - no bundled agency overhead
- **Global expert network**: Access senior-level PMs, architects, UX experts from lower cost-of-living regions at fair rates
- **Transparent marketplace pricing**: Experts bid competitively, not agency markup
- **Standardized workflow**: BMAD methodology ensures consistency without agency process overhead

**vs. Consultant Networks (Toptal, A.Team):**
- **Full-stack workflow**: Not just development talent - planning experts too
- **Escrow + validation**: Payment protection and quality gates, not just vetting
- **Indie maker pricing**: $100 + 5% per stage vs. 20-30% consultant fees
- **AI-assisted execution**: Experts leverage AI tools to deliver faster, cheaper

**Why This Pricing Model Works**

**Multi-Stage Expert Marketplace Economics:**

By tapping into a global network of experts across all specializations - PMs, architects, UX designers, developers, QA reviewers - including senior talent in regions with lower costs of living, we can offer complete project delivery at 40-60% of typical agency rates.

**Example Project Economics:**

Traditional Agency ($50k total):
- Discovery & Planning: $15k
- Design: $10k
- Development: $20k
- QA: $5k

Platform Marketplace ($20-25k total):
- Analyst (optional): $500 (expert bid)
- PM (PRD): $1,000 (expert bid) + $155 platform fee = $1,155
- Architect: $800 (expert bid) + $145 platform fee = $945
- UX Design: $1,200 (expert bid) + $165 platform fee = $1,365
- Development (10 stories @ avg $1,500): $15,000 + $1,750 platform fees = $16,750
- QA (via marketplace bidding, ~$100/story): Covered in platform fees
- **Total: ~$20,215 (vs. $50k agency)**

**Platform Revenue:** $2,215 in fees (11% effective rate on $20k project)
**Expert Earnings:** $18,500 distributed across PM, architect, UX, developers
**Client Savings:** $30k (60% cost reduction)

**Financial Inclusion Through Crypto:** Many talented experts (especially in regions with unstable fiat) prefer cryptocurrency payments. We support native crypto payments (stablecoins and major tokens) for escrow and payouts, removing barriers and giving experts control over their earnings. This isn't about speculation - it's about financial access and stability for global talent.

Everyone wins: clients get complete expert services at indie-maker prices, experts earn competitive income globally, and the platform proves that respecting human expertise doesn't mean being unaffordable.

**High-Level Vision for the Product**

A thriving global expert marketplace where:
- **Idea holders** confidently bring products to life with complete expert guidance from concept to deployment
- **Experts worldwide** (PMs, architects, UX designers, developers, QA reviewers) earn sustainable income applying their specialized skills
- **Role fluidity thrives**: Same person can be client on one project, PM on another, developer on a third, QA reviewer on a fourth
- **The ecosystem** establishes reputation across multiple expertise areas, creating compounding value and career growth opportunities

As AI capabilities improve, the platform evolves naturally - experts shift from primary execution to validation and oversight roles across all disciplines, but human expertise remains the cornerstone of quality and trust at every stage.

---

## Target Users

Our primary market is the global indie maker community serving as both clients and multi-role experts (PMs, architects, UX designers, developers, QA reviewers).

### **Primary User Segment: Indie Makers (Client Side)**

**Demographic/Firmographic Profile:**
- Solo entrepreneurs, side hustlers, and small team founders (1-3 people)
- Ages 25-45, tech-savvy but not necessarily developers themselves
- Global distribution with concentration in US, EU, Latin America, Southeast Asia, Eastern Europe
- Annual revenue $0-$500k (pre-revenue startups to early traction)
- Budget-conscious but quality-focused

**Current Behaviors and Workflows:**
- Use no-code tools (Webflow, Bubble) for MVPs but hit limitations quickly
- Hire freelancers on Upwork/Fiverr with mixed results and high communication overhead
- Attempt to learn coding themselves but find it too time-consuming
- Network in indie maker communities (Indie Hackers, Twitter/X, Discord servers)
- Comfortable with AI tools (ChatGPT, Claude) for ideation and planning

**Specific Needs and Pain Points:**
- Need to validate product ideas quickly without spending $20k+ on agencies
- Struggle to articulate technical requirements clearly to developers
- Fear scope creep, budget overruns, and getting "ghosted" by freelancers
- Want quality code they can build on, not throwaway prototypes or AI slop
- Need developers who understand startup constraints and move fast

**Goals They're Trying to Achieve:**
- Ship v1 of product in 2-4 months with $5k-$15k budget
- Get to revenue/validation before running out of runway
- Build reputation in their niche and grow sustainable business
- Eventually hire full-time team if product succeeds

---

### **Secondary User Segment: Indie Makers (Expert Side - Multi-Role)**

**Demographic/Firmographic Profile:**
- Experienced practitioners across multiple disciplines (3-15 years experience)
- Ages 25-50, distributed globally with significant representation from lower cost-of-living regions
- Currently freelancing, contracting, or employed while seeking additional income streams
- Entrepreneurial mindset - many have shipped their own products and understand full lifecycle
- **Specialist areas**: Product management, technical architecture, UX design, development (full-stack/specialist), quality assurance

**Current Behaviors and Workflows:**
- Supplement primary income with freelance consulting or development (nights/weekends)
- Use Upwork, Toptal, Catalant (for PMs), personal networks for finding work
- Spend 40-60% of engagement time on client communication, scope clarification, context gathering
- Frustrated by vague requirements, endless revisions, scope creep
- Prefer async work due to timezone differences or personal schedule constraints
- Already use AI assistants (Claude, ChatGPT, Cursor, Figma AI) to increase productivity

**Specific Needs and Pain Points:**
- Want well-scoped engagements with clear deliverables and "done" criteria
- Need payment protection (escrow) for planning work, not just development
- Prefer working in flow state with comprehensive documentation, not constant calls
- Seek steady pipeline across multiple skill areas (PM one project, dev another)
- Want multi-dimensional reputation (PM skills + dev skills + QA skills tracked separately)

**Goals They're Trying to Achieve:**
- Earn $3k-$10k/month across multiple expert roles (PM + dev, or architect + QA, etc.)
- Build portfolio demonstrating multiple competencies (planning AND execution)
- Work on interesting problems with autonomy and respect across different phases
- Maximize utilization (fill gaps with different role types - PM work while waiting for dev project)
- Eventually transition to full-time independent multi-role consultant

**Role Examples:**
- **Sarah**: Senior full-stack dev (day job) → Earns extra as PM creating PRDs ($1k-2k per PRD), occasional QA review ($100-200/story)
- **Marco**: Solutions architect (consulting) → Creates architecture docs ($800-1500 per project), develops complex backend stories ($2k-4k/story)
- **Priya**: UX designer → Design docs ($1k-2k per project), QA reviews from UX perspective ($100-150/story), occasional PM work

---

### **Why Indie Makers as Primary Market**

**Community cohesion:** Indie makers share values (ship fast, learn publicly, respect craft, support each other), which creates a healthier marketplace culture than traditional client vs. vendor dynamics across all expert roles.

**Multi-role network effects:** Indie makers naturally possess multiple skills - developers who've done PM work, designers who code, architects who QA. One signup activates potential across 6 different marketplaces. A dev waiting for projects can earn as QA reviewer; a PM can take architect roles; everyone maximizes utilization.

**Market timing:** This community is already comfortable with AI tools (ChatGPT, Claude, Cursor), async collaboration, comprehensive documentation, and global remote work - reducing adoption friction across all workflow stages.

**Underserved across entire lifecycle:** Agencies serve complete lifecycle but price out indie makers. Freelance platforms offer developers but not PMs/architects/UX. AI tools can't handle strategic planning. No one serves complete workflow at indie maker prices with expert validation.

---

## Goals & Success Metrics

### **Early Milestone Targets**

**Month 1 (MVP Launch):**
- **Platform foundation**: MVP launched with core features operational (brief creation, project posting, escrow, GitHub integration, QA workflow)
- **Initial supply**: 5-10 developers onboarded and vetted (recruited from personal network)
- **First validation**: 1-2 projects posted with funded escrow
- **Technical stability**: <1% error rate on core workflows, 99%+ uptime
- **Community seed**: 20-30 indie makers in community Slack/Discord

**Month 3 (Early Traction):**
- **Supply growth**: 15+ active developers (accepted at least one project bid)
- **Demand validation**: 5+ projects posted, 2-3 completed with payment released
- **Quality signals**: 100% of completed projects passed QA review, 0 disputes
- **Brief effectiveness**: 80%+ of briefs accepted by developers without major clarification
- **Developer earnings**: At least one developer earned $1k+ in the month
- **Community engagement**: 50+ community members, 10+ active weekly participants
- **Repeat behavior**: At least 1 client or developer returned for second project

---

### **Business Objectives (6-12 Month Targets)**

**1. Achieve marketplace liquidity within 6 months**
- **Target**: 20+ active developers, 10+ projects posted, 5+ completed projects with payment released
- **How to measure**:
  - Active developers = developers who've accepted at least one project in last 30 days (tracked via platform dashboard)
  - Projects posted = unique project briefs created and funded in escrow (database query)
  - Completed projects = projects with final payment released to developer (payment system logs)
- **Data source**: Platform analytics dashboard, updated daily
- **Review cadence**: Weekly review of funnel metrics (applications → accepted → active)
- **Decision trigger**: If <10 developers by month 3, shift resources to developer recruitment

**2. Prove unit economics by month 9**
- **Target**: Platform fee revenue covers direct costs with 30%+ contribution margin
- **How to measure**:
  - Revenue = (Total project value) × (Take rate %)
  - Direct costs = Payment processing fees (2.9% + $0.30 Stripe) + QA reviewer compensation ($50-100/project) + Infrastructure (AWS, estimated $500-1000/month)
  - Contribution margin = (Revenue - Direct costs) / Revenue
- **Data source**: Financial tracking spreadsheet, reconciled monthly
- **Review cadence**: Monthly P&L review
- **Decision trigger**: If contribution margin <15% by month 6, evaluate QA cost optimization or take rate adjustment

**3. Establish trust system validation**
- **Target**: 80%+ project completion rate, 4.5+ average rating from both clients and developers
- **How to measure**:
  - Completion rate = (Projects with final payment released) / (Projects with developer matched) × 100
  - Average rating = Mean of 1-5 star ratings collected post-project via automated email survey
  - Separate tracking for client ratings of developers and developer ratings of platform/clients
- **Data source**: Platform database + post-project survey responses (Typeform)
- **Review cadence**: Monthly metric review, quarterly deep dive on abandonment reasons
- **Decision trigger**: If completion rate <60% by month 6, conduct user interviews to diagnose (brief quality? mismatch? scope issues?)

**4. Demonstrate supply-side value**
- **Target**: Developers earning average $3k+/month on platform by month 12, 60%+ developer retention
- **How to measure**:
  - Average monthly earnings = (Total developer payouts in month) / (Number of active developers that month)
  - Developer retention = (Developers who accept 2+ projects) / (Total developers who've completed 1 project) × 100
  - Tracked separately: Distribution of earnings (avoid "average" hiding concentration)
- **Data source**: Payment disbursement logs, developer cohort analysis
- **Review cadence**: Monthly earnings distribution report, quarterly retention cohort analysis
- **Decision trigger**: If <50% retention by month 9, interview churned developers to understand (insufficient project flow? pricing? quality of projects?)

**5. Build community engagement**
- **Target**: 100+ indie makers in community (Slack/Discord), 40%+ using both sides of marketplace
- **How to measure**:
  - Community members = Total Slack/Discord members (auto-tracked)
  - Both-sides usage = (Users who've been client AND developer) / (Total users) × 100
  - Engagement quality = Weekly active users in community, message volume, #-of-help-requests-answered
- **Data source**: Slack/Discord analytics API, platform user activity database
- **Review cadence**: Weekly community health check, monthly engagement metrics
- **Decision trigger**: If <30% both-sides usage by month 9, evaluate whether to simplify onboarding for developer side

---

### **User Success Metrics**

**Client satisfaction: 85%+ would recommend platform, 2-4 month average time from idea to shipped v1**
- **How to measure**:
  - NPS survey sent after project completion: "On scale 0-10, how likely would you recommend this platform?"
  - Recommend rate = (Promoters 9-10) / (Total responses) × 100
  - Time-to-ship = (Date of final payment release) - (Date of initial brief creation)
- **Data source**: Post-project NPS survey (automated email 2 days after payment release), platform timestamps
- **Review cadence**: Monthly NPS tracking, quarterly analysis of time-to-ship distribution
- **Success indicator**: NPS >50 is world-class for marketplaces, 85% recommend = NPS 70+

**Developer satisfaction: 70%+ of time spent building vs. communication, escrow payment released within 48 hours of QA approval**
- **How to measure**:
  - Time allocation survey sent to developers post-project: "What % of project time was spent: building, clarifying requirements, revisions, other?"
  - Payment release speed = (Timestamp of payment release) - (Timestamp of QA approval)
  - Track: % of payments released within 24h, 48h, 72h, >72h
- **Data source**: Developer post-project survey, payment system logs
- **Review cadence**: Monthly survey analysis, weekly payment speed monitoring
- **Success indicator**: Compare to baseline (freelance platforms: ~40-60% time spent building, 50% on communication)

**Brief quality: 90%+ of AI-assisted briefs accepted by developers without major clarification requests**
- **How to measure**:
  - Developer acceptance survey when accepting project: "How clear is this brief? Rate 1-5. Did you need major clarifications before accepting?"
  - Brief acceptance rate = (Briefs rated 4-5 AND no major clarifications needed) / (Total briefs presented to developers) × 100
  - Track clarification requests logged in platform before project acceptance
- **Data source**: Developer brief evaluation survey (mandatory before accepting project), clarification message count in platform
- **Review cadence**: Weekly brief quality monitoring, monthly analysis of common clarification patterns
- **Decision trigger**: If <75% by month 6, analyze AI brief generation prompts and improve templates

**QA effectiveness: 95%+ of QA-approved work accepted by clients without disputes**
- **How to measure**:
  - Client acceptance = (Projects where client accepts QA-approved work without dispute) / (Total QA-approved projects) × 100
  - Dispute types tracked: technical quality, scope mismatch, functionality issues
- **Data source**: Dispute resolution system logs, client acceptance workflow
- **Review cadence**: Weekly QA effectiveness tracking, monthly dispute pattern analysis
- **Decision trigger**: If <90% by month 6, review QA reviewer training and checklist rigor

**Async collaboration validation: 80%+ of projects completed without synchronous client-developer calls**
- **How to measure**:
  - Post-project survey asks both sides: "Did you have any scheduled calls during this project? If yes, how many?"
  - Async success rate = (Projects with zero scheduled calls) / (Total completed projects) × 100
- **Data source**: Post-project survey from both client and developer
- **Review cadence**: Monthly async validation tracking
- **Success indicator**: This validates core hypothesis that quality briefs eliminate communication need

---

### **Key Performance Indicators (KPIs)**

**Marketplace Health:**

- **Supply/Demand Ratio: 2-3 developers per active project**
  - Measurement: (Active developers in last 30 days) / (Active projects in last 30 days)
  - Tracked weekly via dashboard
  - Alert if ratio <1.5 (supply shortage) or >5 (demand shortage)

- **Time-to-Match: Average 48-72 hours from project posted to developer matched**
  - Measurement: (Timestamp of developer acceptance) - (Timestamp of project posted with funded escrow)
  - P50, P75, P90 percentiles tracked to understand distribution
  - Weekly monitoring, monthly trend analysis

- **Project Completion Rate: 80%+ of matched projects reach payment release**
  - Measurement: (Projects with final payment released) / (Projects where developer accepted and started work) × 100
  - Cohort analysis by month to track improvement
  - Flag abandoned projects for investigation

**Financial:**

- **Average Project Value (APV): $8k-$12k per project**
  - Measurement: (Total escrow funded) / (Number of projects) in given period
  - Track distribution (min, P25, P50, P75, max) to avoid mean distortion
  - Monthly tracking, quarterly analysis of trends

- **Platform Take Rate: 15-20%**
  - Measurement: (Platform fee collected) / (Total project value) × 100
  - May vary by project size (tiered: 20% for <$5k, 15% for >$15k)
  - Tracked per transaction, analyzed monthly

- **Monthly Recurring Projects: 15+ projects per month by month 12**
  - Measurement: Count of projects with escrow funded in calendar month
  - Weekly forecast update, monthly actuals review
  - Leading indicator: Projects in brief-creation phase (predicts 2-4 weeks ahead)

**Quality & Trust:**

- **QA Pass Rate: 85%+ of first submissions pass QA review**
  - Measurement: (Projects passing QA on first submission) / (Total projects submitted to QA) × 100
  - Track rework cycles (1st try, 2nd try, 3+ tries)
  - Weekly monitoring, developer-specific tracking to identify coaching needs

- **Dispute Rate: <5% of projects enter dispute resolution**
  - Measurement: (Projects entering formal dispute process) / (Total projects) × 100
  - Categorize disputes: payment, scope, quality, communication
  - Monthly tracking, quarterly deep-dive on dispute causes

- **Repeat Usage: 40%+ clients post second project within 6 months, 60%+ developers accept second project**
  - Measurement: Cohort analysis tracking first-time users and their return behavior
  - Client repeat = (Clients with 2+ projects) / (Clients with ≥1 completed project and ≥6 months tenure)
  - Developer repeat = (Developers with 2+ projects) / (Developers with ≥1 completed project)
  - Quarterly cohort reports

**Growth:**

- **Developer Application Rate: 50+ applications per month by month 6**
  - Measurement: Count of developer signup applications submitted (before screening)
  - Weekly tracking via CRM/applicant tracking system
  - Source attribution (referral, organic, paid ads, community) to optimize acquisition

- **Developer Acceptance Rate: 30-40%**
  - Measurement: (Developers approved and onboarded) / (Total applications) × 100
  - Tracks quality bar maintenance
  - Monthly review of acceptance reasons and rejection patterns

- **Word-of-Mouth Coefficient: 30%+ of new users from referrals by month 9**
  - Measurement: New user signup source tracking: "How did you hear about us?" (required field)
  - Referral = responses indicating "friend/colleague recommendation" or tracked referral link
  - Monthly analysis of acquisition sources, calculate (Referral signups) / (Total signups) × 100
  - Virality coefficient: (Invites sent by existing users) / (Existing users) to predict future growth

---

### **Measurement Infrastructure**

**MVP measurement stack:**
- **Analytics**: Mixpanel or Amplitude for event tracking (brief created, project posted, developer matched, payment released)
- **Surveys**: Typeform for post-project NPS and satisfaction surveys (auto-triggered)
- **Financial**: Stripe Dashboard + Google Sheets reconciliation for unit economics
- **Community**: Slack/Discord native analytics + Orbit.love for community health
- **Dashboard**: Retool or Metabase for internal KPI dashboard (weekly team reviews)

**Data collection practices:**
- Automated event tracking for all user actions (instrumented in platform code)
- Mandatory post-project surveys (incentivize with $10 platform credit)
- Weekly manual reconciliation of financial data
- Monthly metric review meeting with decision triggers documented

---

## MVP Scope

This section defines what we build for initial launch vs. what comes later. The MVP must prove the complete trust loop - partial implementation won't validate the core value proposition.

### **Core Features (Must Have for MVP)**

**1. AI-Assisted Brief Creation**

- **What**: Interactive workflow guiding clients through project specification using AI assistant
- **Why essential**: The quality brief is the foundation - without this, we're just another freelance marketplace

**Technical Implementation:**
- **Frontend**: React-based multi-step form wizard with real-time AI suggestions
- **AI Integration**: Claude API (Anthropic) with custom system prompts for brief generation
  - Prompt engineering based on BMAD methodology templates
  - Structured output parsing to JSON/Markdown
  - Iterative refinement flow (AI suggests → user edits → AI improves)
- **Data model**: Brief schema (Postgres) storing PRD sections, epics, stories as structured JSON
- **Workflow engine**: State machine tracking brief creation progress (draft → review → published → funded)
- **Estimated complexity**: 3-4 weeks (1 week prompt engineering, 2 weeks UI/workflow, 1 week testing)
- **Key dependencies**: Claude API access, robust error handling for AI failures
- **Success criteria**: 90%+ of generated briefs accepted by developers without major clarification

---

**2. Project Marketplace (Posting & Matching)**

- **What**: Platform for clients to post funded projects and developers to bid/be matched
- **Why essential**: Core marketplace functionality - connects supply and demand

**Technical Implementation:**
- **Frontend**: Project listing page (Next.js) with filters (tech stack, budget, timeline)
- **Backend**: REST API (Node.js/Express) for project CRUD operations
- **Data model**:
  - Projects table (id, client_id, brief_id, status, budget, tech_stack[], created_at)
  - Bids table (id, project_id, developer_id, proposed_timeline, message, status)
  - Developer profiles (skills, hourly_rate, availability, portfolio_links)
- **Matching logic** (MVP = simple, manual):
  - Developers manually browse and bid
  - Client reviews bids and selects developer
  - Alternative: Auto-suggest top 3 developers based on tech stack match (simple keyword matching)
- **Real-time updates**: WebSocket or polling for new project notifications to developers
- **Estimated complexity**: 2-3 weeks (straightforward CRUD with filtering)
- **Key dependencies**: None (standard web stack)
- **Success criteria**: Average 48-72 hour time-to-match

---

**3. Escrow Payment System**

- **What**: Secure payment holding and release mechanism with multi-currency support
- **Why essential**: Solves trust problem for both sides - protects clients and guarantees developer payment

**Technical Implementation:**

**Fiat Payments:**
- **Provider**: Stripe Connect (handles marketplace splits, escrow-like holding)
- **Flow**:
  1. Client funds escrow → Stripe charge with `capture_method: manual` or use Stripe Connect transfers
  2. Funds held in platform Stripe account
  3. On QA approval → transfer to developer Stripe Connect account
- **Implementation**: Stripe SDK integration, webhook handlers for payment events
- **Compliance**: Stripe handles PCI compliance, platform registered as payment facilitator

**Cryptocurrency Payments - Wallet-Native Integration:**

**Supported Wallets:**
- **Metamask** (Ethereum, Polygon, BSC, Arbitrum, other EVM chains)
- **Phantom** (Solana)
- **WalletConnect** (universal fallback for 300+ wallets)

**Web3 Integration Stack:**
- **Ethereum/EVM chains**:
  - Library: ethers.js or viem (modern, TypeScript-first)
  - Wallet connection: RainbowKit or wagmi (handles Metamask, WalletConnect, Coinbase Wallet)
  - Networks: Ethereum mainnet, Polygon (lower gas fees for escrow)
- **Solana**:
  - Library: @solana/web3.js
  - Wallet connection: @solana/wallet-adapter-react (handles Phantom, Solflare, etc.)
  - Network: Solana mainnet

**Smart Contract Escrow (Recommended for Security):**

Instead of platform-controlled wallets, use escrow smart contracts for trustless, transparent payments:

**Benefits:**
- ✅ **Trustless**: Funds locked in smart contract, not platform wallet (more secure)
- ✅ **Transparent**: Anyone can verify escrow status on-chain
- ✅ **Non-custodial**: Platform never holds funds (reduces regulatory burden)
- ✅ **Automated**: Payout happens via smart contract call, not manual transfer

**Payment Flow:**

*Client Funding Escrow:*
1. Client clicks "Fund with Crypto" → selects network (Ethereum/Polygon/Solana)
2. Metamask/Phantom popup appears
3. Client sends stablecoin (USDC/USDT) to project-specific escrow smart contract
4. Platform detects on-chain transaction via RPC node WebSocket (Alchemy/Infura for Ethereum, Helius for Solana)
5. After confirmations (12 for ETH, 1 for Polygon, 32 for Solana), escrow marked as funded

*Developer Payout:*
1. QA approval triggers smart contract state update (platform calls `approveQA()`)
2. Developer clicks "Claim Payment" → Metamask/Phantom popup
3. Smart contract releases funds directly to developer's wallet
4. Transaction hash recorded for audit trail

**Data Model:**
```typescript
Escrow {
  id: uuid
  project_id: uuid
  story_id: uuid
  amount: decimal
  currency: 'USD' | 'USDC' | 'USDT' | 'ETH' | 'SOL'
  network: 'stripe' | 'ethereum' | 'polygon' | 'solana'
  payment_method: 'fiat' | 'crypto'

  // Crypto-specific fields
  contract_address: string  // Escrow smart contract address
  client_wallet: string
  developer_wallet: string
  funding_tx_hash: string
  release_tx_hash: string

  status: 'pending' | 'funded' | 'released' | 'refunded'
  funded_at: timestamp
  released_at: timestamp
}
```

**Gas Fee Strategy:**
- **Polygon**: ~$0.01-0.05 per transaction (affordable for platform to subsidize)
- **Solana**: ~$0.0001 per transaction (negligible)
- **Ethereum L1**: $5-50+ per transaction (use Polygon or L2s like Arbitrum instead)

**Estimated complexity**:
- Fiat: 1-2 weeks (Stripe well-documented)
- Crypto: 3-4 weeks
  - 1 week: Write & test smart contracts (Solidity + Solana, or use OpenZeppelin templates)
  - 1 week: Deploy to testnets, security review
  - 1 week: Frontend integration (RainbowKit + wallet-adapter)
  - 1 week: Testing, edge cases (failed transactions, gas estimation)
- Total: 4-5 weeks

**Key dependencies**:
- Stripe Connect approval (can take 1-2 weeks)
- RPC node access (Alchemy, Infura for Ethereum; Helius, QuickNode for Solana)
- Smart contract templates (OpenZeppelin escrow contracts are audited and battle-tested)

**Success criteria**: Payment released within 48 hours of QA approval, <5% dispute rate

---

**4. GitHub Integration**

- **What**: Automated repository setup and code delivery workflow
- **Why essential**: Standardizes delivery mechanism and provides transparency

**Technical Implementation:**
- **GitHub API Integration**: OAuth app with repo creation permissions
- **Flow**:
  1. Client connects GitHub account or provides repo URL
  2. Platform creates private repo (via GitHub API) or gets access to existing
  3. Invite developer as collaborator
  4. Create GitHub issues for each story (auto-generated from brief)
  5. Developer submits work via PR
  6. PR webhook triggers QA review workflow
- **Data model**:
  - GitHub credentials (OAuth tokens, encrypted at rest)
  - Story-to-issue mapping (story_id → github_issue_url)
  - PR tracking (pr_id, story_id, status, merged_at)
- **Alternative for non-GitHub clients**: GitLab/Bitbucket support or platform-hosted Git (Gitea) - defer to post-MVP
- **Estimated complexity**: 2 weeks (GitHub API straightforward, webhook handling needs testing)
- **Key dependencies**: GitHub OAuth app approval (instant), webhook reliability
- **Success criteria**: 100% of projects delivered via GitHub with full commit history

---

**5. QA Validation Workflow**

- **What**: Independent quality review process before payment release
- **Why essential**: The trust gate that differentiates us from freelance platforms - ensures quality

**Technical Implementation:**

**AI-Assisted Analysis (Automated Layer):**
- **Tools**:
  - Linting: ESLint, Prettier, language-specific linters (via GitHub Actions)
  - Security scanning: Snyk, GitHub Dependabot
  - Test coverage: Istanbul/NYC, Jest coverage reports
  - Code quality: SonarQube or CodeClimate
- **Integration**: GitHub Actions workflow triggered on PR submission
- **Output**: JSON report with pass/fail criteria, flagged issues

**Human QA Review (Manual Layer):**
- **QA reviewer interface**: Web dashboard showing:
  - Brief requirements
  - Code diff (GitHub PR embedded)
  - Automated scan results
  - Pass/fail checklist aligned to brief
- **Reviewer pool**: Initially founder/trusted developers (manual assignment)
- **Compensation**: Fixed fee per review ($50-100 depending on project complexity)
- **SLA**: 24-48 hour review turnaround

**Workflow:**
1. Developer submits PR → automated scans run
2. Platform assigns QA reviewer
3. Reviewer evaluates: code quality, brief alignment, functionality
4. Decision: Approve (release payment) | Request revisions (with feedback) | Reject (escalate to dispute)
5. Developer notified, client notified

**Data Model:**
- QA reviews table (id, project_id, story_id, reviewer_id, status, automated_results_json, notes, decision, reviewed_at)

**Estimated complexity**: 3-4 weeks
- 1 week: GitHub Actions automation setup
- 2 weeks: QA reviewer dashboard and workflow
- 1 week: Testing and reviewer onboarding

**Key dependencies**: GitHub Actions runners, QA reviewer availability

**Success criteria**: 95%+ of QA-approved work accepted by clients, 85%+ first-submission pass rate

---

**6. Reputation System**

- **What**: Trust-building through demonstrated delivery history
- **Why essential**: Enables marketplace scaling beyond personal networks - reputation replaces references

**Technical Implementation:**
- **Data model**:
  - User profiles (developer/client) with computed stats:
    - Total projects completed
    - Average rating (1-5 stars)
    - On-time delivery rate
    - First-pass QA success rate (developers)
    - Prompt payment (clients)
  - Ratings table (id, project_id, from_user_id, to_user_id, rating, review_text, created_at)
  - Badges table (user_id, badge_type, earned_at) - e.g., "Top Developer", "Verified Identity"
- **Profile page**: Public-facing developer/client profiles (Next.js pages)
  - Portfolio section: Links to GitHub repos, live URLs, screenshots
  - Reviews: Paginated list of past project feedback
  - Skills/tech stack tags
- **Rating flow**: Post-project automated email → survey link → ratings stored → profile updated
- **Gamification (optional for MVP)**: Badges, leaderboards (defer if time-constrained)
- **Estimated complexity**: 2 weeks (standard feature, well-trodden path)
- **Key dependencies**: None
- **Success criteria**: 60%+ developer repeat rate, 40%+ client repeat rate

---

**7. Epic/Story Task Breakdown**

- **What**: Decomposition of projects into granular, independently deliverable tasks
- **Why essential**: Enables milestone payments, multiple developers per project, risk reduction

**Technical Implementation:**
- **AI-Assisted Decomposition**:
  - Input: PRD (from brief creation)
  - Claude API prompt: "Decompose this PRD into epics and stories. Each story should be independently deliverable in 3-7 days."
  - Output: Structured JSON (epics[], each with stories[])
  - User editing interface to refine, reorder, add/remove stories
- **Data model**:
  - Epics table (id, project_id, title, description, order)
  - Stories table (id, epic_id, title, description, acceptance_criteria, estimated_days, assigned_developer_id, status, github_issue_url)
  - Dependencies table (story_id, depends_on_story_id) - tracks "Story B can't start until Story A complete"
- **Dependency visualization**: Simple directed graph (D3.js or Mermaid) showing story relationships
- **Story assignment**:
  - **MVP approach**: All stories assigned to one developer (simpler)
  - **Post-MVP**: Per-story bidding (enables multiple devs per project)
- **Estimated complexity**: 3 weeks
  - 1 week: AI decomposition + editing UI
  - 1 week: Data model and story management
  - 1 week: Dependency tracking and visualization
- **Key dependencies**: Claude API, GitHub integration (for issue creation)
- **Success criteria**: 80%+ of projects broken into 3+ stories, clients report increased confidence from granularity

---

### **Technical Architecture Overview**

**Stack:**
- **Frontend**: Next.js (React), TypeScript, Tailwind CSS
- **Backend**: Node.js/Express REST API, TypeScript
- **Database**: PostgreSQL (hosted on Railway/Supabase for MVP speed)
- **Auth**: NextAuth.js (supports OAuth, email/password, magic links)
- **File storage**: AWS S3 or Cloudflare R2 (for project assets, screenshots)
- **Hosting**: Vercel (frontend), Railway (backend + DB), or all-in-one Render
- **CI/CD**: GitHub Actions
- **Monitoring**: Sentry (errors), PostHog or Mixpanel (analytics)
- **Web3**: RainbowKit (Ethereum wallets), @solana/wallet-adapter (Solana), Alchemy/Helius (RPC nodes)

**Why this stack:**
- **Speed**: Next.js + Railway = deploy in minutes, not days
- **Cost**: Free tiers cover MVP (Vercel, Railway, Supabase generous for early stage)
- **Flexibility**: TypeScript + Postgres allows complex features later without rewrite
- **Hiring**: Popular stack = easy to find developers if needed
- **Web3-ready**: Modern wallet libraries with great DX

**Security Considerations:**
- Smart contract security: Use audited OpenZeppelin templates, test on testnets first
- API keys/secrets: Environment variables, never committed to repo
- User auth: JWT tokens with short expiry, refresh tokens
- Payment data: PCI compliance via Stripe (don't store card numbers), crypto is non-custodial
- SQL injection prevention: Parameterized queries (Prisma ORM)

**Estimated Total MVP Development Time:**
- **With full-time solo founder developer**: 12-16 weeks
- **With 2 developers**: 8-10 weeks
- **With experienced contractor team (3 people)**: 6-8 weeks

---

### **Build vs. Buy Decisions**

**Build (Custom):**
- ✅ AI brief generation (core differentiator)
- ✅ QA workflow (unique to our trust model)
- ✅ Epic/story decomposition (specific to our methodology)
- ✅ Marketplace matching logic (evolves with product)
- ✅ Smart contract escrow (Solidity + Solana programs)
- ✅ Wallet connection UI (RainbowKit + wallet-adapter integration)

**Buy/Integrate (Existing Tools):**
- ✅ Payments: Stripe Connect (fiat)
- ✅ RPC nodes: Alchemy/Infura (Ethereum), Helius (Solana)
- ✅ Wallet libraries: RainbowKit, @solana/wallet-adapter
- ✅ Smart contract templates: OpenZeppelin escrow contracts (audited, battle-tested)
- ✅ GitHub: API integration (don't build version control)
- ✅ Auth: NextAuth.js (don't build OAuth flows)
- ✅ Email: SendGrid or Resend (transactional emails)
- ✅ Analytics: Mixpanel/PostHog (don't build from scratch)
- ✅ Code scanning: GitHub Actions + existing linters (don't write analyzers)

**Rationale:** Build only what differentiates, buy infrastructure. Saves 4-6 weeks of development time.

---

### **Out of Scope for MVP**

**Deferred to Post-Launch:**
- Brief consultation service (paid PRD review by experts)
- Community voting/feedback on projects
- Formal BMAD training/certification for developers
- Revenue-share/equity payment options
- Advanced developer matching algorithm (ML-based skill matching)
- Mobile app (web-only for MVP)
- White-label/API for agencies
- Multi-language support (English only for MVP)
- Per-story bidding with multiple developers per project (MVP = one developer per project)
- Additional blockchain networks beyond Ethereum/Polygon/Solana

**Rationale for deferral:** These are revenue opportunities and optimizations, but not required to prove core value proposition. MVP validates: quality briefs + async execution + QA validation = successful projects.

---

### **MVP Success Criteria**

The MVP successfully validates the concept if:
- ✅ **End-to-end completion**: At least 3 projects completed fully (brief → match → build → QA → payment)
- ✅ **Quality validation**: 0 disputes, 4.5+ average satisfaction from both sides
- ✅ **Async validation**: Projects completed without client-developer calls
- ✅ **Economics validation**: Unit economics show path to profitability (contribution margin >20%)
- ✅ **Repeat behavior**: At least 1 client or developer returns for second project
- ✅ **Crypto adoption**: At least 1 project funded and paid via cryptocurrency

**If MVP succeeds, we've proven**: Structured briefs + skilled developers + QA validation = reliable alternative to agencies and freelance chaos.

---

## Post-MVP Vision

This section outlines the product evolution after MVP validation. The platform naturally evolves from "human builds" to "human validates" as AI capabilities improve.

### **Phase 2 Features (Months 6-12)**

**Per-Story Bidding & Multi-Developer Projects:**
- Allow different developers to bid on individual stories within an epic
- Dependency coordination system (Story B dev can't start until Story A merged)
- Lead developer role for complex multi-dev projects
- **Value**: Enables specialization, faster delivery, resilience (if one dev drops out, only one story affected)

**Brief Consultation Service:**
- Paid PRD review by experienced product managers before posting
- $200-500 service for clients who want expert feedback on scope/feasibility
- Becomes pre-qualifier for complex projects
- **Value**: New revenue stream, higher quality briefs, reduces abandoned projects

**Advanced Matching Algorithm:**
- ML-based developer recommendations (beyond simple tech stack keyword matching)
- Factors: past project similarity, developer availability, success rate, communication style
- Smart pricing suggestions based on project complexity and developer experience
- **Value**: Faster matching, better fit quality, reduced client decision paralysis

**Community Features:**
- Public project showcases (with client permission)
- Developer portfolios with live demos
- Community voting on "Project of the Month"
- Learning resources and BMAD methodology training
- **Value**: Marketing flywheel, developer skill-building, stronger community cohesion

---

### **Long-Term Vision (Years 1-2)**

**The Evolution to Quality Certification Layer:**

As AI coding capabilities improve (2026-2027), the platform's value shifts:
- **Phase 1 (2025)**: Humans build with AI assistance
- **Phase 2 (2026)**: AI builds with human review/validation
- **Phase 3 (2027+)**: Platform becomes trust certification layer

**What this looks like:**
- Projects increasingly use AI agents for initial implementation
- Developers shift from writing code to validating AI-generated code
- QA becomes "AI quality certification" - human experts verify AI work meets production standards
- Platform brand becomes "UL Certification for AI-generated software"

**Why this positioning is defensible:**
- Regulatory requirements will demand human accountability (insurance, liability, compliance)
- High-stakes projects always want human oversight
- Trust certification is more valuable long-term than execution services
- Developer skills evolve up the stack (judgment > implementation)

**New Business Model Opportunities:**
- Certification badges for AI-validated code
- Insurance/guarantee products for AI-generated projects
- White-label validation services for AI coding tool companies
- Enterprise compliance validation (SOC2, HIPAA for AI-built software)

---

### **Expansion Opportunities (2-3 Years)**

**Geographic Expansion:**
- Localize platform for non-English markets (Spanish, Portuguese, Hindi priority)
- Regional community chapters (Latin America, Southeast Asia, Europe)
- Partnership with local dev bootcamps for talent pipeline

**Vertical Specialization:**
- Industry-specific marketplaces (fintech, healthtech, e-commerce)
- Compliance-first projects (HIPAA, SOC2, GDPR built-in)
- Mobile-first projects (iOS/Android specialists)

**Enterprise Offering:**
- White-label platform for agencies (they use our infrastructure, their brand)
- API access for project management tools (Linear, Jira integration)
- Team accounts (startups hiring multiple devs through platform)

**Revenue Diversification:**
- Revenue-share/equity payment options (devs bet on project success)
- Developer training/certification program (BMAD methodology)
- Marketplace for reusable components (devs sell their micro-libraries)

---

### **North Star Vision (5 Years)**

**"The global standard for human-validated software development"**

A thriving ecosystem where:
- **10,000+ developers worldwide** earn sustainable income through validated expertise
- **Clients** trust the platform brand as quality guarantee (like AWS for infrastructure, we're the standard for human-validated code)
- **AI companies** partner with us for validation layer (OpenAI, Anthropic recommend us for production deployments)
- **Enterprises** require our certification for vendor-developed software
- **Indie makers** build billion-dollar companies that started as platform projects

**The platform has proven:** Human expertise doesn't compete with AI - it validates, guides, and guarantees AI-augmented development. We monetized the human-in-loop when everyone else tried to eliminate it.

---

## Technical Considerations

This section documents technical requirements, constraints, and preferences for the platform. These are initial thoughts that will be refined during architecture design.

### **Platform Requirements**

**Target Platforms:**
- **Web application** (primary): Desktop and mobile-responsive browser access
- **MCP server**: Model Context Protocol server for Claude Desktop/ChatGPT integration
- **No native mobile apps for MVP** (defer to post-MVP based on user demand)
- **Browser support**: Modern browsers only (Chrome, Firefox, Safari, Edge - last 2 versions)

**Performance Requirements:**
- **Page load**: <2 seconds for main pages (Next.js SSR optimization)
- **API response time**: <500ms for p95 (database queries optimized)
- **MCP tool execution**: <3 seconds for p95 (same backend as REST API)
- **Blockchain transaction monitoring**: Real-time updates within 30 seconds of on-chain confirmation
- **AI brief generation**: <10 seconds for initial draft (Claude API typically 3-5s)
- **File uploads**: Support up to 50MB for project assets

**Scalability Targets:**
- **MVP (0-6 months)**: 100 concurrent users, 50 projects/month
- **Year 1**: 1,000 concurrent users, 500 projects/month
- **Year 2**: 10,000 concurrent users, 2,000 projects/month

---

### **Technology Preferences**

**Frontend:**
- **Framework**: Next.js 14+ (App Router)
- **Language**: TypeScript (type safety critical for complex data models)
- **Styling**: Tailwind CSS + shadcn/ui components (rapid UI development)
- **State management**: React Context + Zustand for global state
- **Forms**: React Hook Form + Zod validation

**Backend:**
- **Runtime**: Node.js 20+ (LTS)
- **Framework**: Express.js or Fastify (Express for familiarity, Fastify for performance)
- **Language**: TypeScript
- **API style**: REST for MVP (GraphQL deferred - adds complexity)
- **ORM**: Prisma (TypeScript-native, great DX, handles migrations)

**Database:**
- **Primary**: PostgreSQL 15+ (JSONB for flexible brief storage, proven reliability)
- **Hosting**: Supabase or Railway (generous free tiers, easy scaling)
- **Caching**: Redis for session management and rate limiting (optional for MVP)
- **Search**: PostgreSQL full-text search initially (ElasticSearch deferred)

**Infrastructure:**
- **Frontend hosting**: Vercel (Next.js optimized, edge network, zero config deploys)
- **Backend hosting**: Railway or Render (Heroku-like DX, better pricing)
- **Database**: Bundled with Railway/Supabase
- **File storage**: Cloudflare R2 (S3-compatible, no egress fees) or AWS S3
- **CDN**: Vercel edge network (included) + Cloudflare (for R2)

**Blockchain Infrastructure:**
- **Ethereum/Polygon RPC**: Alchemy (generous free tier, reliable WebSockets)
- **Solana RPC**: Helius or QuickNode
- **Smart contracts**: Solidity (Hardhat for development), Anchor (Solana)
- **Wallet libraries**: RainbowKit (EVM), @solana/wallet-adapter (Solana)

**Third-Party Services:**
- **Payments**: Stripe Connect
- **AI**: Claude API (Anthropic) - primary for brief generation
- **Email**: Resend (modern API, good deliverability) or SendGrid
- **Analytics**: PostHog (self-hostable, good free tier) or Mixpanel
- **Error tracking**: Sentry
- **Authentication**: NextAuth.js

---

### **MCP Server (Model Context Protocol) Integration**

**Why Essential:**
- **Zero learning curve UX**: Users create briefs directly in Claude Desktop or ChatGPT without leaving their AI chat interface
- **Inline with #2 priority from brainstorming**: MCP server enables frictionless brief creation
- **Competitive advantage**: While competitors require learning a new platform, we meet users where they already are

**MCP Server Architecture:**

**Complete API Parity Requirement:**
- **Every REST API endpoint has equivalent MCP tool/resource**
- **Single source of truth**: Both MCP server and REST API call same backend service layer
- **Consistent behavior**: Authentication, validation, errors identical across both interfaces

**Implementation Approach:**

```
┌─────────────────┐      ┌──────────────────┐      ┌─────────────────┐
│  Web Frontend   │      │   MCP Server     │      │  Service Layer  │
│   (Next.js)     │──────│  (FastMCP)       │──────│  (Shared Logic) │
└─────────────────┘      └──────────────────┘      └─────────────────┘
         │                        │                         │
         └────────────────────────┴─────────────────────────┘
                            │
                     ┌──────▼──────┐
                     │  PostgreSQL │
                     └─────────────┘
```

**Architecture:**
- **Shared service layer**: Business logic extracted to `packages/services`
  - `BriefService.create()`, `ProjectService.list()`, `EscrowService.fund()`, etc.
- **MCP server** (`apps/mcp-server`): Exposes tools that call service layer
- **REST API** (`apps/api`): Express endpoints that call same service layer
- **Benefits**: No duplicate logic, guaranteed consistency, single test suite for business logic

**MCP Server Capabilities:**

**Tools (Actions users can take):**
- `create_brief` - Start AI-assisted brief creation workflow
- `list_projects` - Browse available projects (developer view)
- `bid_on_project` - Submit bid for a project
- `fund_escrow` - Trigger payment flow (wallet connect handled via URL)
- `submit_work` - Create PR and notify platform
- `check_qa_status` - Get status of QA review
- `view_reputation` - See developer/client profile and ratings

**Resources (Data users can access):**
- `brief://[id]` - Read specific brief details
- `project://[id]` - Read project details and status
- `escrow://[id]` - Check escrow funding/release status
- `developer://[username]` - View developer profile

**Prompts (Templates for common workflows):**
- `Create a new project brief` - Guides user through brief creation with AI assistance
- `Find projects matching my skills` - Developer discovery workflow
- `Check my active projects` - Status dashboard

**Authentication:**
- **API key approach**: User generates API key in web platform, configures in MCP settings
- **OAuth flow** (alternative): More secure, but requires browser redirect from Claude Desktop
- **MVP choice**: API key (simpler), OAuth post-MVP

**Technical Stack:**

**MCP Server Framework:**
- **Primary**: FastMCP (`fastmcp`) - better DX, faster development
- **Fallback**: Official Anthropic SDK (`@modelcontextprotocol/sdk`)
- **Abstraction layer**: Custom adapter pattern to enable SDK swapping without rewriting business logic
- **Language**: TypeScript (shares types with main platform)
- **Transport**: stdio (for Claude Desktop) + SSE (for web clients)
- **Hosting**:
  - **Self-hosted option**: Users run locally (npm package published)
  - **Cloud-hosted option**: Platform-hosted MCP server (users connect via URL)

**Rationale for FastMCP:**
- Decorator-based API reduces boilerplate by ~60% vs official SDK
- Auto-generates JSON schemas from TypeScript types (less duplication)
- Faster MVP development (saves 1-2 weeks on MCP integration)
- Abstraction layer mitigates third-party dependency risk
- Can migrate to official SDK post-MVP if needed

**Deployment:**
- **NPM package**: `@american-nerd/mcp-server` - users install and run locally
- **Platform-hosted**: `mcp.platform.com` - users configure in Claude Desktop settings
- **Both options supported**: Self-hosted for privacy-conscious users, cloud-hosted for convenience

**Estimated Complexity:**
- **3-4 weeks development**:
  - 1 week: Refactor existing logic into service layer
  - 1 week: Build MCP server with core tools (FastMCP)
  - 1 week: Testing, authentication, error handling
  - 1 week: Documentation, npm packaging, deployment
- **Parallel to web development**: Can build MCP server alongside REST API (shared services make this efficient)

---

### **Architecture Considerations**

**Repository Structure:**

**Monorepo approach** (Turborepo):
- `apps/web` - Next.js frontend
- `apps/api` - Express backend (REST API)
- `apps/mcp-server` - MCP server (Model Context Protocol)
- `packages/services` - **Shared business logic (critical for API/MCP parity)**
- `packages/database` - Prisma schema and client
- `packages/types` - Shared TypeScript types
- `packages/ui` - Shared component library
- `packages/contracts` - Smart contracts (Solidity + Anchor)

**Benefits:**
- Single source of truth for business logic (`packages/services`)
- Type safety across REST API, MCP server, and frontend
- Atomic commits that update all interfaces simultaneously
- Test suite validates both API and MCP server

**Service Architecture:**
- **MVP**: Monolithic backend (all logic in one Express app)
- **Post-MVP**: Consider microservices for:
  - Brief generation service (Claude API integration)
  - Payment/escrow service (Stripe + blockchain monitoring)
  - QA automation service (GitHub Actions integration)
- **Rationale**: Start monolithic, split when scaling pain emerges

**Integration Requirements:**
- **GitHub API**: OAuth app, webhook receivers for PR events
- **Stripe webhooks**: Payment event handling (async, idempotent)
- **Blockchain event monitoring**: WebSocket connections to RPC nodes
- **Claude API**: Rate limiting handling, fallback for API failures
- **MCP protocol**: stdio transport for Claude Desktop, SSE for web clients

**Security Requirements:**
- **Authentication**: JWT-based with refresh tokens
- **Authorization**: Role-based access control (client, developer, QA reviewer, admin)
- **Data encryption**:
  - At rest: Database encryption (Supabase/Railway default)
  - In transit: TLS 1.3 only
  - Secrets: Environment variables via Vercel/Railway, consider Vault for production
- **Smart contract security**: Use audited OpenZeppelin contracts, testnet deployment first
- **API security**: Rate limiting (100 req/min per user), CORS configuration
- **SQL injection**: Parameterized queries via Prisma (prevents injection)
- **XSS prevention**: React escapes by default, CSP headers configured
- **MCP API keys**: Scoped permissions, revocable, rate-limited

---

### **Updated MVP Development Timeline**

**With full-time solo founder developer:** 14-18 weeks
- Core platform: 10-12 weeks
- MCP server + service layer refactoring: 3-4 weeks
- Integration testing & deployment: 1-2 weeks

**With 2 developers:** 9-12 weeks
- Parallel development: One focuses on MCP server while other builds web platform
- Shared service layer developed collaboratively

**With experienced contractor team (3 people):** 7-9 weeks
- Dedicated developer for MCP server integration
- Frontend and backend teams work in parallel

---

## Constraints & Assumptions

### **Constraints**

**Budget:**
- **MVP development**: $0-$20k (bootstrapped or angel/pre-seed)
  - $0 if founder builds solo
  - $10-20k if hiring 1-2 contractors for 2-3 months
- **Monthly operational costs (MVP)**: $200-500/month
  - Infrastructure: Vercel/Railway/Supabase free tiers → $0-100/month
  - Claude API: ~$100-200/month (brief generation usage)
  - RPC nodes (Alchemy/Helius): Free tier sufficient for MVP
  - Domain, email, misc: ~$50/month
- **Post-launch runway**: Assumes 6-12 months to reach break-even on unit economics

**Timeline:**
- **Target MVP launch**: 14-18 weeks from start (solo founder) or 7-9 weeks (3-person team)
- **First revenue**: Month 2 post-launch (assumes at least 1 paid project completes)
- **Market window**: 12-18 months before AI coding capabilities significantly improve (need to establish platform before shift to validation model)

**Resources:**
- **Team**: 1-3 people for MVP (founder + optional contractors)
- **Founder time commitment**: Full-time (40+ hours/week) for duration of MVP build
- **QA reviewers**: 2-3 trusted developers recruited from network (compensated per review)
- **Legal/compliance**: Minimal for MVP (standard T&Cs, privacy policy), defer complex crypto/marketplace regulation until traction

**Technical:**
- **No mobile apps**: Web-only for MVP (mobile-responsive design sufficient)
- **English-only**: Multi-language support deferred
- **Limited blockchain networks**: Ethereum/Polygon/Solana only (no Bitcoin, BSC, Arbitrum for MVP)
- **Manual processes acceptable**: Developer vetting, project matching, QA assignment can be manual initially

---

### **Key Assumptions**

**Market Assumptions:**
- Indie makers experience the pain points described (vague requirements, communication overhead, trust anxiety)
- $5k-$15k project budget range is accessible to target market
- Global developers from lower-cost regions are willing to work on platform for fair-but-lower-than-US rates
- Cryptocurrency adoption among target developers is high enough (30%+ willing to accept crypto payments)
- "AI slop" stigma persists for 12-24 months, creating demand for human-validated development

**Product Assumptions:**
- AI-assisted brief generation via Claude produces quality specs 90%+ of the time
- Async collaboration works without synchronous communication for 80%+ of projects
- QA validation layer provides sufficient trust for payment release
- Epic/story decomposition adds value (clients feel more confident with granular milestones)
- MCP server adoption reduces onboarding friction significantly

**Business Model Assumptions:**
- 15-20% platform take rate is acceptable to both clients and developers
- Escrow + QA validation justifies platform fee (vs. lower fees on Upwork/Fiverr without these features)
- Developers willing to accept $50-100 QA fee per story as cost of payment guarantee
- Unit economics reach 30%+ contribution margin by month 9

**Technical Assumptions:**
- Claude API remains available and affordable (no pricing changes that break economics)
- Vercel/Railway free tiers sufficient for first 3-6 months (100 users, 50 projects/month)
- Stripe Connect approves platform as payment facilitator
- Smart contract gas fees remain low on Polygon/Solana (<$0.10 per transaction)
- GitHub API rate limits don't constrain platform usage
- FastMCP library remains maintained and compatible with Claude Desktop

**Competitive Assumptions:**
- Traditional freelance platforms (Upwork, Fiverr) won't copy our quality brief + QA validation model quickly
- AI coding tools (Cursor, Devin) won't achieve 95%+ quality without human review within 18 months
- No well-funded competitor launches similar "GitHub Actions for human development" concept before we reach market
- BMAD methodology provides defensible positioning (not easily replicated)

**Regulatory/Legal Assumptions:**
- Platform can operate as payment facilitator without becoming a regulated financial institution
- Cryptocurrency escrow doesn't trigger money transmitter regulations (non-custodial smart contracts mitigate this)
- Marketplace model doesn't create employer-employee relationship (contractors remain independent)
- No immediate regulatory changes that would materially impact crypto payments or gig economy platforms
- Standard T&Cs and arbitration clauses sufficient for dispute resolution

**Team/Execution Assumptions:**
- Founder has sufficient technical skills to build MVP (or can hire competent contractors)
- Can recruit 10-20 initial developers from personal network or indie maker communities
- QA reviewers provide consistent quality and 24-48h turnaround
- Founder can wear multiple hats (product, eng, bizdev, support) during MVP phase

---

### **Assumptions Requiring Validation**

**High-priority validation (test during MVP):**
1. **Brief quality**: Do AI-generated briefs actually reduce developer clarification requests by 80%+?
2. **Async viability**: Can projects complete without sync calls, or do certain project types require it?
3. **QA effectiveness**: Does QA validation prevent disputes, or do we see high dispute rates anyway?
4. **Pricing elasticity**: Is $8-12k APV realistic, or does market demand lower pricing?
5. **Crypto adoption**: Will 30%+ of developers actually choose crypto payments?

**Medium-priority validation (data by month 6):**
1. **Developer retention**: Do developers return for 2nd+ projects, or is churn high?
2. **Client satisfaction**: Does 85%+ NPS materialize, or are expectations too high?
3. **Unit economics**: Can we achieve 30%+ contribution margin, or are costs higher than projected?

**Lower-priority (observable over time):**
1. **Market timing**: Does AI improvement timeline match our 12-24 month assumption?
2. **Role fluidity**: Do users actually switch between client/developer roles at meaningful rates?

---

## Risks & Open Questions

### **Key Risks**

**Market Risks:**

- **AI capability acceleration**: If AI coding tools reach 95%+ quality faster than expected (within 6-12 months), demand for human developers may decline before platform establishes moat
  - **Mitigation**: Build reputation/certification system from day 1, position for evolution to validation model early
  - **Impact if realized**: High - could undermine core value proposition

- **Indie maker market size**: Target market may be smaller than assumed, or willingness to pay $5k-$15k lower than expected
  - **Mitigation**: Validate pricing with 10-20 indie makers pre-launch, offer flexible milestone-based payments
  - **Impact if realized**: Medium - may need to expand to startups or lower prices

- **Cryptocurrency volatility**: Stablecoin de-pegging or regulatory crackdown on crypto payments could impact developer appeal
  - **Mitigation**: Support both fiat and crypto, don't rely exclusively on crypto adoption
  - **Impact if realized**: Low-Medium - affects developer access in certain regions, not existential

**Product Risks:**

- **AI brief quality**: Claude-generated briefs may not achieve 90% developer acceptance, requiring excessive manual refinement
  - **Mitigation**: Human brief review service, iterative prompt engineering, fallback to manual brief creation
  - **Impact if realized**: Medium - increases client effort, undermines "frictionless" positioning

- **Async collaboration failure**: Certain project types may require synchronous communication, limiting addressable market
  - **Mitigation**: Identify async-friendly project patterns, comprehensive BMAD documentation eliminates need for human-to-human handoffs
  - **Impact if realized**: Low - BMAD docs serve as "mother ship" for all context

- **QA bottleneck**: Human QA reviewers can't scale or provide consistent quality at volume
  - **Mitigation**: QA reviewer marketplace with bidding, build robust automated QA layer, recruit reviewer pool early
  - **Impact if realized**: Medium - QA marketplace model should handle scaling naturally

**Competitive Risks:**

- **Incumbent response**: Upwork/Fiverr copy our quality brief + QA validation features
  - **Mitigation**: Move fast to establish brand, leverage BMAD methodology differentiation, build community moat
  - **Impact if realized**: High - reduces differentiation, increases customer acquisition costs

- **Well-funded competitor**: VC-backed startup launches similar concept with more resources
  - **Mitigation**: Focus on niche (indie makers), build defensible community, emphasize crypto/global access, multi-stage marketplace complexity
  - **Impact if realized**: High - could outspend on marketing and expert acquisition

**Technical Risks:**

- **Claude API changes**: Anthropic raises prices, deprecates features, or restricts API access
  - **Mitigation**: Build abstraction layer for AI providers, add GPT-4 as fallback
  - **Impact if realized**: Medium - increases costs or requires re-engineering, but solvable

- **Smart contract vulnerability**: Escrow contract exploited, funds stolen
  - **Mitigation**: Use audited OpenZeppelin contracts, testnet testing, bug bounty program, insurance
  - **Impact if realized**: Catastrophic - loss of funds destroys trust and creates legal liability

- **Blockchain gas fee spike**: Ethereum/Polygon gas fees surge, making small transactions uneconomical
  - **Mitigation**: Use Solana (ultra-low fees), batch transactions, client pays gas for funding
  - **Impact if realized**: Low - Solana fallback and client-pays model mitigates

**Regulatory/Legal Risks:**

- **Payment facilitator regulations**: Stripe discontinues service or regulators classify platform as money transmitter
  - **Mitigation**: Legal counsel review, maintain reserves, obtain necessary licenses if required
  - **Impact if realized**: High - could force payment infrastructure rebuild or cease operations

- **Crypto regulations**: New laws restrict cryptocurrency payments or smart contract escrows
  - **Mitigation**: Fiat-first strategy, crypto as optional, non-custodial smart contracts reduce regulatory surface
  - **Impact if realized**: Medium - limits developer access in certain regions but doesn't kill platform

- **Contractor classification**: Experts classified as employees, not independent contractors
  - **Mitigation**: Clear contractor agreements, avoid control over how work is performed, consult employment lawyer
  - **Impact if realized**: High - massive compliance costs, retroactive tax liability

**Execution Risks:**

- **Expert supply shortage**: Can't recruit enough quality experts (PMs, architects, UX, devs, QA) for marketplace liquidity across all stages
  - **Mitigation**: Supply-side first GTM (recruit experts before seeking clients), incentivize early adopters, role fluidity helps
  - **Impact if realized**: High - marketplace fails without supply at each stage

- **Founder burnout**: Solo founder building complex multi-stage marketplace for 14-18 weeks full-time
  - **Mitigation**: Scope discipline (ruthless MVP focus), co-founder or contractor support, sustainable pace
  - **Impact if realized**: High - delays launch or compromises quality

---

### **Open Questions - RESOLVED**

The following questions were discussed and resolved during brief creation:

**1. Projects too small for epic/story breakdown?**
- **Decision**: All projects get full BMAD treatment regardless of size. BMAD agents handle project scoping at any scale, making this a differentiator.

**2. Should clients request specific developers for follow-up work?**
- **Decision**: No direct requests - all projects go through standard matching. Reputation system allows organic reconnection.

**3. Wallet connection UX in MCP server?**
- **Decision**: Support both deep link handoff AND QR code display. MCP returns clickable URL + inline QR code for maximum flexibility.

**4. Preventing "spec gaming" by developers?**
- **Decision**: QA reviewer assesses both letter AND spirit of spec, using comprehensive BMAD docs (PRD, architecture, design) for full context. Human judgment is the value.

**5. Platform fee structure?**
- **Decision**: **$100 per story + 5% of story value** (hybrid model). More fair than flat percentage, ensures minimum revenue per story for QA costs.

**6. Who pays gas fees for crypto transactions?**
- **Decision**: Client pays gas for funding escrow, developer pays gas for claiming payment. Each party pays for their own on-chain actions.

**7. QA reviewer compensation sustainability?**
- **Decision**: QA reviewer marketplace with bidding. Market-driven pricing ensures sustainability and scales naturally.

**8. Preventing race to bottom on developer pricing?**
- **Decision**: No intervention - let market decide. Quality + reputation will differentiate. Trust free market dynamics.

**9. Multi-developer epic integration risks?**
- **Decision**: Sequential dependencies - stories completed in order. Each dev builds on previous work, ensuring integration integrity.

**10. Timezone coordination for dependency handoffs?**
- **Decision**: No coordination needed. BMAD documentation (PRD, architecture, design docs) serves as "mother ship" for all context. True async collaboration.

**11. Dispute resolution when client rejects QA-approved work?**
- **Decision**: **QA decision is final** - payment auto-releases. Client responsibility to provide sufficient documentation. Upsell opportunity: Expert marketplace for PRD/architecture/design doc review.

---

### **Critical Platform Evolution Discovery**

**The platform is not just a developer marketplace - it's a multi-stage BMAD workflow marketplace:**

**Planning Phase Marketplaces:**
1. **Analyst** (optional): Brainstorming and market research
2. **PM**: PRD creation from brief
3. **Architect**: Architecture doc creation from PRD
4. **UX Expert**: Design doc creation from PRD + Architecture

**Development Phase Marketplaces:**
5. **Developer**: Story implementation
6. **QA Reviewer**: Story validation

**Each stage:**
- AI-assisted execution (BMAD agents)
- Human expert validation/improvement
- Marketplace bidding for expert selection
- Escrow-protected payment
- Platform fee: $100 + 5% of expert bid value

**This transforms the value proposition**: Platform monetizes the entire BMAD planning workflow, not just development execution. Each BMAD agent role becomes an earning opportunity for human experts.

---

### **Areas Needing Further Research**

**Market Research:**
- Validate multi-stage marketplace demand: Will clients pay for PM/architect/UX experts, or just want developers?
- Expert supply analysis: Are there enough PMs, architects, UX experts in indie maker community willing to earn via platform?
- Pricing validation: What will experts charge for PRD creation ($500? $1500?)? Architecture docs ($300? $1000?)?
- Competitive analysis: Do any platforms offer similar multi-stage expert marketplaces?

**Product/UX Research:**
- Multi-stage workflow UX: How to present 6-stage workflow without overwhelming clients?
- Optional vs. required stages: Should PM/architect/UX be optional, or required for quality guarantee?
- Bundle pricing: Should we offer "full planning package" (analyst + PM + architect + UX) at discount?

**Technical Feasibility:**
- Workflow orchestration complexity: Managing state across 6 different marketplaces with escrow at each stage
- Document handoff automation: How to ensure PRD → Architecture → Design dependencies are tracked and validated?
- MCP server parity: Can MCP server handle full workflow, or just certain stages?

**Financial Modeling:**
- Updated unit economics: Platform fee revenue across all 6 stages vs. single dev marketplace
- Expert take rates: Will $100 + 5% work for $1k+ expert engagements (PRD creation), or need different model?
- Client budget impact: Does $2-5k in planning docs + $10k in development = $12-15k total deter indie makers?

---

## Appendices

### **A. Research Summary**

This Project Brief was created based on a comprehensive brainstorming session conducted on 2025-10-05, which explored the complete business model, platform features, technical architecture, and go-to-market strategy.

**Key Brainstorming Insights:**
- **7 techniques used**: Five Whys, Morphological Analysis, SCAMPER, Assumption Reversal, Time Shifting, Action Planning, Resource Constraints
- **50+ ideas generated** across market positioning, product features, technical implementation, and business model
- **Core insight discovered**: Monetize the human-in-loop across the entire BMAD workflow, not just development execution
- **Evolution path validated**: Platform naturally shifts from "human builds" to "human validates" as AI improves

**Critical Discovery During Brief Creation:**
- Platform is not just a developer marketplace - it's a **multi-stage BMAD workflow marketplace**
- Each BMAD agent role (Analyst, PM, Architect, UX, Developer, QA) becomes an expert earning opportunity
- This transforms value proposition from "better freelancing" to "complete expert-validated project delivery"

**Supporting Documentation:**
- Full brainstorming session results: `docs/brainstorming-session-results.md`
- BMAD methodology reference: Available via MCP tool `mcp__BMAD-METHOD_Docs__fetch_BMAD_METHOD_documentation`

---

### **B. BMAD Workflow Integration**

**Planning Workflow:**
```
Client Idea → Brief Creation (AI + optional Analyst)
  ↓
PM Expert creates PRD from Brief
  ↓
Architect Expert creates Architecture from PRD
  ↓
UX Expert creates Design from PRD + Architecture
  ↓
PO/Master Checklist validates alignment
  ↓
Epics & Stories generated
```

**Development Workflow:**
```
Stories posted to Developer Marketplace
  ↓
Developers bid and are matched
  ↓
Sequential development (Story 1 → Story 2 → Story 3...)
  ↓
Each story: Dev implements → QA reviews → Payment releases
  ↓
Complete project delivered with full documentation
```

**Document Dependencies:**
- Brief → PRD (PM expert)
- PRD → Architecture (Architect expert)
- PRD + Architecture → Design (UX expert)
- All docs → Stories (decomposition)
- All docs → Development (implementation guide)
- All docs → QA (validation criteria)

---

### **C. Competitive Landscape**

**Direct Competitors:**
- **Upwork/Fiverr**: Freelance marketplaces (developers only, no planning experts, weak quality control)
- **Toptal/A.Team**: Vetted talent networks (developers/designers, expensive, no workflow orchestration)
- **Catalant**: Expert marketplace (consultants only, enterprise-focused, no development execution)

**Adjacent Competitors:**
- **Development Agencies**: Complete service but $50k+ pricing
- **AI Coding Tools** (Cursor, Devin, Copilot): Speed but no human validation, "AI slop" concerns
- **No-code platforms** (Bubble, Webflow): Limited functionality, not suitable for complex products

**Our Differentiation:**
- ✅ Complete workflow coverage (planning + development + QA)
- ✅ Multi-role expert marketplace (6 different specializations)
- ✅ Escrow protection at every stage
- ✅ AI-assisted + human-validated (anti-slop positioning)
- ✅ Indie maker pricing ($20-25k vs. $50k+ agencies)
- ✅ BMAD methodology as standardized workflow
- ✅ Global expert access + crypto payments

**Competitive Moats:**
- **Network effects**: Multi-role marketplace with high utilization
- **Methodology lock-in**: BMAD becomes industry standard
- **Reputation system**: Cross-role reputation is hard to replicate
- **Community**: Indie maker cohesion and values alignment
- **Workflow complexity**: Orchestrating 6 marketplaces with dependencies is hard to copy

---

### **D. References**

**BMAD Methodology:**
- GitHub Repository: `bmad-code-org/BMAD-METHOD`
- Documentation access: Via MCP tool for latest specifications
- Core concept: AI-assisted agents for each project role with human validation

**Market Research Sources:**
- Indie Hackers community (target market validation)
- Upwork/Fiverr pricing data (competitive baseline)
- Freelancer income surveys (target earnings validation)
- Crypto adoption statistics (payment method validation)

**Technical References:**
- Stripe Connect documentation (payment infrastructure)
- OpenZeppelin smart contracts (escrow security)
- FastMCP library (MCP server implementation)
- RainbowKit/wallet-adapter (crypto wallet integration)

---

## Next Steps

### **Immediate Actions (Pre-Development)**

**1. Market Validation (Weeks 1-2)**
- **Indie maker interviews**: Talk to 20 indie makers about multi-stage marketplace concept
  - Would they pay for PM/architect/UX experts separately?
  - What price points are acceptable for planning stages?
  - Crypto payment preferences validation
- **Expert supply research**: Recruit 5-10 experts across each role (PM, architect, UX, dev, QA)
  - Gauge interest in marketplace bidding model
  - Validate expected earnings ranges
  - Identify early adopter incentives needed

**2. Financial Modeling (Week 2)**
- Build detailed unit economics spreadsheet with multi-stage revenue
- Model different client journey scenarios (full workflow vs. dev-only vs. planning-only)
- Calculate platform revenue across 6 marketplaces
- Determine break-even timeline and runway requirements

**3. Technical Prototyping (Weeks 2-3)**
- Prototype AI brief generation with Claude API (test quality with 10 sample briefs)
- Smart contract escrow proof-of-concept (deploy to testnet)
- MCP server basic implementation (test with one marketplace stage)
- Workflow orchestration design (state machine for 6-stage dependencies)

**4. Legal/Compliance Review (Week 3)**
- Consult lawyer on marketplace model (contractor classification across all roles)
- Payment facilitator requirements for Stripe Connect
- Crypto escrow regulations (non-custodial smart contracts)
- Terms of Service, Privacy Policy, Expert Agreements drafting

---

### **MVP Development Plan (Weeks 4-21: 14-18 weeks)**

**Phase 1: Foundation (Weeks 4-8)**
- Monorepo setup (Turborepo with apps/packages structure)
- Shared service layer architecture (business logic for API + MCP parity)
- Database schema (Postgres with Prisma)
- Authentication system (NextAuth.js)
- Basic UI framework (Next.js + Tailwind + shadcn/ui)

**Phase 2: Planning Marketplaces (Weeks 9-12)**
- Brief creation workflow (AI-assisted with Claude API)
- PM marketplace (PRD creation bidding, escrow, delivery)
- Architect marketplace (architecture doc bidding, escrow, delivery)
- UX marketplace (design doc bidding, escrow, delivery)
- Document dependency tracking and validation

**Phase 3: Development Marketplaces (Weeks 13-17)**
- Story decomposition from planning docs
- Developer marketplace (bidding, matching, sequential dependencies)
- GitHub integration (repo creation, PR tracking, webhooks)
- QA marketplace (reviewer bidding, automated checks, human review)
- Payment escrow (Stripe + crypto smart contracts)

**Phase 4: MCP Server & Integration (Weeks 18-20)**
- MCP server with FastMCP (complete API parity)
- Wallet integration (RainbowKit + Phantom support with QR codes)
- End-to-end workflow testing
- Performance optimization

**Phase 5: Launch Prep (Week 21)**
- Security audit (smart contracts, payment flows)
- Beta testing with recruited experts and clients
- Documentation (user guides, expert onboarding)
- Community setup (Slack/Discord)

---

### **Go-to-Market Strategy**

**Supply-Side First Approach:**

**Month -1 (Pre-Launch):**
- Recruit 10-15 experts across all roles from personal network:
  - 2-3 PMs
  - 2-3 Architects
  - 2-3 UX designers
  - 5-8 Developers
  - 3-5 QA reviewers
- Incentivize early adopters: First 10 experts get 0% platform fee for first 3 projects

**Month 1 (Launch):**
- Seed 2-3 projects from founder network (know quality of demand)
- Experts deliver to build initial reputation
- Document success stories and case studies
- Achieve Month 1 metrics: 5-10 developers, 1-2 projects posted

**Month 2-3 (Early Traction):**
- Indie Hackers, Twitter/X, Product Hunt launch
- Content marketing: "How we built X using the platform" stories
- Expert referrals: Experts invite other experts
- Achieve Month 3 metrics: 15+ active experts, 2-3 completed projects

**Months 4-6 (Growth):**
- Community-led growth through indie maker networks
- Expert success stories (earning $3k-5k/month across roles)
- Client testimonials (saved $30k vs. agency)
- Achieve Month 6 metrics: 20+ experts, 5+ completed projects, marketplace liquidity

---

### **Success Criteria for Brief Handoff**

This Project Brief is complete and ready to hand off to the next phase (Product/Engineering) when:

✅ **Validation complete**: 20 indie maker interviews confirm demand for multi-stage marketplace
✅ **Expert supply confirmed**: 10-15 experts recruited and committed across all roles
✅ **Financial model validated**: Unit economics show path to 30%+ contribution margin
✅ **Technical feasibility proven**: Smart contract POC, AI brief generation tested, MCP server prototype working
✅ **Legal review done**: Lawyer confirms marketplace model, contractor agreements drafted

**Handoff Deliverables:**
- This Project Brief (complete)
- Financial model spreadsheet (unit economics across 6 marketplaces)
- Expert recruitment list (committed early adopters)
- Technical prototypes (brief generation, smart contract, MCP server)
- Legal documentation (T&Cs, privacy policy, expert agreements)

---

**PM/Dev Team Next Action:** Review this brief thoroughly, validate assumptions through user research, begin technical architecture design for multi-stage workflow orchestration.

---

*Project Brief created using BMAD methodology with Business Analyst agent facilitation*
*Session date: 2025-10-05*
*Version: 2.0 (Multi-Stage Marketplace Model)*

